glm4.6活脱脱降智版 Claude sonnet
总是“你说得完全正确”，“太对了”

我问它能不能删掉某个变量的定义，它说“完全可以”，而下一行就是对这个变量的操作。。。

--
sonnet 4.5 之前设计并实现了一个巨tm过度考虑未来扩展性的方案，隔了十天我完全看不懂这段代码。
于是让这glm这个快速模型给我讲代码，结果越讲越听不懂了🤦‍♂️🤦‍♂️🤦‍♂️
自己测试了一下发现它完全是在糊弄我🤬

--
现在AI最大的问题是 如果用户不懂某个领域，AI 会不经意间教会用户很多错误知识。

有用智谱GLM4.6的吗？这实际体验跟宣传和跑分也差太多了
怎么跟千问一样的操作，跑分没输过，体验没赢过。而且最离谱的是这个模型还能免费体验。想试一下得先充值，而且这个token的消耗也是离谱，同样的问题，在回答别Gemini短很多的情况下，token消耗还多非常

---

订阅了glm 4.6 coding plan，巨卡巨慢无比
特别是到了下午，每一步都是漫长的等待

---

智谱清言的glm4.6有点差呀，远远不如4.5，4.6我现在用来写代码做出来的很多问题，他写出来的代码很多报错，然后让他解决bug的话，要多次才能解决一个bug，还不如人的脑袋解决问题快了，4.6的体验非常的差完全降智。4.5的版本不是这样的，4.5的版本让他解决一个bug，一次性就能解决。并且让他添加一些新的功能添加出来几乎没有什么报错，偶尔还是有报错，但是远远不如4.6这么多，在4.6版本里面，我让他添加一些打印日志，添加打印日志之后，居然出现了作用域的问题，这也是我没想到的，这不是很基础的编程知识吗

---

GLM-4.6 vs MiniMax M2 Coding Plan 对比
最近在做AI Agent项目，需要选择合适的大模型API。花了一整天时间对GLM-4.6和MiniMax M2进行了实测对比，现在把数据分享给大家。
📋 测试说明
测试环境：新西兰奥克兰，当地时间下午6点（对应国内凌晨时段）
测试方式：使用30k+字符的长prompt和22个工具定义，进行5轮连续对话，模拟真实的代码开发场景，包括架构解释、工具调用、代码编写、文件查询和测试编写。
重要提示：响应时间和token输出量有直接关系。如果模型输出更多token（更详细的内容），响应时间自然会更长，这是正常现象。就像你让AI写一篇100字的总结和1000字的详细说明，后者肯定需要更多时间。所以不能单纯用响应速度来评判模型好坏，要结合输出质量和token数量综合考虑。

---

GLM-4.5真实体验：低价不一定省钱，效率翻
